%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																				%
%	TRABAJO:	Trabajo Final													%
%				Especialidad en Ingeniería en Sistemas de Información			%
%																				%
%		Titulo:																	%
%																				%
%		Autores:	Julian Nonino												%
%																				%
%	Capitulo sobre Apache Spark													%	
%																				%
%	Año: 2016																	%
%																				%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Apache Spark}
\label{chapter_apache_spark}

Spark es una herramienta de código abierto desarrollada para procesar datos de
manera rápida y fácil. Su desarrollo comenzó en 2009 en el AMPLab de la
Universidad de Berkeley, siendo liberado su código en 2010 como un proyecto
Apache.

Spark provee herramientas para procesar diversos conjuntos de datos de distinta
naturaleza (textos, grafos, etcétera) y datos de distintas fuentes,
procesamiento de datos por lotes o procesamiento de un flujo de datos en tiempo
real.

Las aplicaciones para Spark pueden ser escritas en Java, Scala o Python y el
paquete incluye mas de 80 operadores de alto nivel para trabajar con los datos.
Además de operaciones \emph{Map and Reduce} sobre Hadoop, soporta consultas SQL,
flujos de datos y \emph{Machine Learning} \cite{Penchikala2015SparkIntro}.

