%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																				%
%	TRABAJO:	Trabajo Final													%
%				Especialidad en Ingeniería en Sistemas de Información			%
%																				%
%		Titulo:	Procesamiento de Datos en Tiempo Real							%
%																				%
%		Autor:	Julián Nonino													%
%																				%
%	Conclusiones y Trabajo Futuro												%
%																				%
%	Año: 2016																	%
%																				%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusiones y Trabajo Futuro}

\section{Conclusiones}
\label{conclusiones}

	En este trabajo se ha logrado implementar una prueba de concepto utilizando
	Docker como mecanismo de generación de la infraestructura. Se ha mostrado cómo
	utilizar una tecnología como \emph{Apache Kafka} para recibir y reenviar
	mensajes para que sean procesados en el sistema. También, el despliegue y
	configuración de \emph{Apache Storm} para procesar dichos mensajes. Además, se
	muestra el uso de \emph{Apache Zookeeper} como mecanismo de coordinación entre
	estos servicios.

	Por otro lado, se muestra código de aplicaciones desarrolladas para la
	publicación y lectura de datos en Apache Kafka. De la misma manera, se
	implementa una topología de Apache Storm para leer datos desde el servicio de
	Apache Kafka y procesarlos en tiempo real, a medida que son recibidos en el
	sistema.

	El procesamiento de flujos de datos es requerido y toma mucha relevancia cuando
	cada dato debe ser procesado rápidamente y/o continuamente, por ejemplo, cuando
	hay que tomar acciones en tiempo real\cite{Wahner2014}, es especialmente
	importante en productos Big Data e Internet de las Cosas (\emph{Internet of
	Things}).

\section{Trabajo Futuro}
\label{trabajo_futuro}

	Este trabajo puede ser continuado y mejorado desde varias aristas, ampliando la
	prueba de concepto hasta llegar a implementar un sistema de procesamiento de
	datos en tiempo real, desplegado en la nube, con capacidad de crecer y decrecer
	de acuerdo a la carga del sistema.
	
	\begin{itemize}
	    \item Diseñar el implementar \emph{bolts} de Apache Storm para tomar
	    \item Utilizar un proveedor de servicios en la nube como Amazon Web Services,
	    Microsoft Azure, Google Cloud Platform, etcétera.
	    \item Plantear, implementar y probar mecanismos de auto escalabilidad
	    (crecimiento y decrecimiento) del sistema de acuerdo con la carga de datos.
	    \item Plantear, implementar y probar un subsistema de almacenamiento de datos
	    utilizando tecnologías bases de datos como Apache HBase, Cassandra, etcétera.
	    \item Plantear, implementar y probar un subsistema de análisis de datos y
	    generación de reportes (\emph{analytics}).
	    \item Diseñar y plantear modificaciones en el sistema de acuerdo a un modelo
	    de micro servicios permitiendo activar y desactivar características del
	    sistema fácilmente. Además, nuevas características podrían ser agregadas sin
	    afectar el resto de la funcionalidad del sistema.
	\end{itemize}
