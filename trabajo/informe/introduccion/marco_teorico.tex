%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%																				%
%	TRABAJO:	Trabajo Final													%
%				Especialidad en Ingeniería en Sistemas de Información			%
%																				%
%		Titulo:																	%
%																				%
%		Autor:	Julián Nonino													%
%																				%
%	Marco Teórico																%	
%																				%
%	Año: 2016																	%
%																				%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Marco Teórico}
\label{chapter_marco_teorico}

\section{Procesamiento de Datos en Tiempo Real}
\label{section_real_time}

	En los últimos tiempos, la demanda de procesamiento de flujos continuos de datos
	(data streams) se ha incrementado considerablemente. Esto se debe a que ya no es
	suficiente con procesar grandes volúmenes de datos, además, deben ser procesados
	rápidamente permitiendo a los sistemas reaccionar ante los eventos lo antes
	posible. Ejemplos de sistemas que necesitan éste nivel de procesamiento son los
	sistemas de detección de fraude, monitoreo de recursos, comercio, etcétera.

	\subsection{Big Data}
	
		El término Big Data, muy utilizado en la actualidad, hace referencia a lo que se
		conoce como las \textbf{\emph{Tres V}}, \emph{Volumen}, \emph{Variedad} y
		\emph{Velocidad}.
		Con ello, se quiere indicar que un sistema Big Data no solo implica trabajar con
		grandes volúmenes de datos, sino que estos datos pueden ser muy variados y se
		deben procesar rápidamente \cite{Wahner2014}.
	
		\begin{figure}[H]
			\centering
			\includegraphics[width=.5\linewidth]{./informe/introduccion/img/real_time/big_data_tres_v}
		\end{figure}

	\subsection{Procesamiento de Flujos de Datos (Stream Processing)}
		
		En contraste a los modelos de procesamiento de datos tradicionales en los cuales
		los datos son primero almacenados y luego procesados y analizados, cuando se
		procesa un flujo de datos, los datos son procesados y analizados mientras entran
		en el sistema. Esto se conoce como procesar datos en movimiento, conectando los
		procesadores de datos con las fuentes que los producen.
					
		Una solución de procesamiento de datos en tiempo real debe ser capaz de:
		\begin{itemize}
		    \item Procesar cantidades enormes de datos permitiendo filtrado, agregación,
		    predicción, alertas, reglas, etcétera.
			\item Respuesta en tiempo real a los mensajes/eventos recibdos.
			\item Asegurar rendimiento y escalabilidad cuando el volumen de datos crece en
			tamaño y/o complejidad.
			\item Integración fácil y rápida con la infraestructura y fuentes de datos
			existentes.
			\item Rápida implementación y puesta en producción de nuevos requisitos de
			procesamiento.
		\end{itemize}
		
\section{Docker}
\label{section_docker}

	Docker es un proyecto de código abierto que automatiza el despliegue de
	aplicaciones dentro de contenedores de software, proporcionando una capa
	adicional de abstracción y automatización de virtualización a nivel de sistema
	operativo en Linux. Docker utiliza características de aislamiento de recursos del
	kernel de Linux, tales como \emph{cgroups} y \emph{espacios de nombres
	(namespaces)} para permitir que \emph{contenedores} independientes se ejecuten
	dentro de una sola instancia de Linux, evitando la sobrecarga de iniciar y
	mantener máquinas virtuales.\cite{WikipediaDocker}
	
	Docker implementa una API de alto nivel para proporcionar contenedores livianos
	que ejecutan procesos de manera aislada.
	Construido sobre las facilidades proporcionadas por el kernel de Linux (nombradas
	anteriormente), un \emph{contenedor} Docker, a diferencia de una máquina virtual,
	no requiere incluir un sistema operativo independiente. En su lugar, se basa en
	las funcionalidades del kernel y utiliza el aislamiento de recursos y namespaces
	separados para aislar de vista la aplicación del sistema operativo.\cite{WikipediaDocker}

	El soporte del kernel de Linux para los \emph{espacios de nombres} aísla de vista
	una aplicación del entorno operativo, incluyendo árboles de proceso, red, ID de
	usuario y sistemas de archivos montados. A su vez, los \emph{cgroups} del kernel
	proporcionan aislamiento de recursos, incluyendo la CPU, la memoria, el bloque de
	E/S y de la red. Desde la versión 0.9, Docker incluye la librería
	\emph{libcontainer} como su propia manera de utilizar directamente las
	facilidades de virtualización que ofrece el kernel de Linux.\cite{WikipediaDocker}

	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{./informe/introduccion/img/docker/vm_vs_docker}
		\caption{Contenedor Docker (derecha) versus Máquina Virtual (izquierda)
		\cite{WhatIsDocker2016}}
	\end{figure}

	Mediante el uso de contenedores, los recursos pueden ser aislados y los servicios
	restringidos. Además, se otorga a los procesos la capacidad de tener una visión
	casi completamente privada del sistema operativo con su propio identificador de
	espacio de proceso, estructura del sistema de archivos e interfaces de red.
	Contenedores múltiples comparten el mismo núcleo, pero cada contenedor puede ser
	restringido a utilizar sólo una cantidad definida de recursos como CPU, memoria y
	E/S.\cite{WikipediaDocker}
	
	Usando Docker para crear y gestionar contenedores se puede simplificar la
	creación de sistemas altamente distribuidos, permitiendo múltiples aplicaciones
	funcionar de forma autónoma en una única máquina física o en varias máquinas
	virtuales. Esto permite que el despliegue de nodos se realice a medida que se
	dispone de recursos o cuando se necesiten, lo que se conoce como un estilo de
	desplieque \emph{Plataforma como Servicio} (\emph{PaaS - Plataform as a
	Service}).\cite{WikipediaDocker}

	\subsection{Imagenes y Contenedores\cite{GetStartedDocker2016}}
	
		Un \emph{contenedor (container)} es una version de un sistema operativo Linux,
		solo con los componentes más básicos. Una \emph{imagen} es software que se carga
		dentro del contenedor al momento de ejecutar el comando \emph{run}.
	
\lstset{language=bash}
\begin{lstlisting}
docker run hello-world
\end{lstlisting}
	
		El comando \emph{run} recibe como parámetro requerido el nombre de la imagen que
		se desea cargar en un contenedor, en éste caso, \emph{hello-world}.
		
		Al correr dicho comando, Docker ejecuta las siguientes acciones:
		\begin{itemize}
		    \item Comprobar si existe en el sistema una imagen con el nombre
		    \emph{hello-world}.
		    \item En caso de que no exista dicha imagen en el sistema descargarla desde
		    el repositorio de imágenes configurado, por defecto es \emph{Docker Hub}, un
		    repositorio propiedad de Docker donde existen miles de imagenes disponibles.
		    Es posible tener repositorios privados utilizando lo que se conoce como
		    \emph{Docker Registry}.
		    \item Cargar la \emph{imagen} en el \emph{contenedor} y ejecutarla.
		\end{itemize}
		
		Por otro lado, una imagen de Docker puede ejecutar desde un simple comando hasta
		cargar un complejo sistema de base de datos.
		
		Para construir una imagen de Docker, es necesario crear un archivo llamado
		\emph{Dockerfile}.
	
\lstset{language=bash}
\begin{lstlisting}
FROM ubuntu:16.04

RUN apt-get -y update

CMD["echo Hola"]
\end{lstlisting}
	
		El Dockerfile anterior buscara una imagen de Ubuntu con la etiqueta (\emph{tag})
		\emph{16.04}. Luego ejecutará un comando para actualizar los paquetes del
		sistema operativo y finalmente mostrará el mensaje \emph{Hola}.
	
		El comando para construir una \emph{imagen} de Docker es:

\lstset{language=bash}
\begin{lstlisting}
docker build -t miimagen .
\end{lstlisting}

		Se ejecutará el comando \emph{build} para construir la imagen. El argumento
		\emph{-t} indica que se le pondrá la etiqueta \emph{miimagen} a la imagen y
		punto al final indica el directorio de contexto de la \emph{imagen}, esto
		permite agregarle archivos al momento de construirla. En éste caso, el contexto
		será el directorio donde se encuentra el Dockerfile.
	
		Luego, es posible cargar la \emph{imagen} en un \emph{contenedor} mediante el
		comando:
	
\lstset{language=bash}
\begin{lstlisting}
docker run miimagen
\end{lstlisting}

	\subsection{Crear nuevas etiquetas}
	
		Para ponerle una nueva etiqueta a una imagen, primero debemos encontrar el
		número de identificación de la misma. Ésto se hace corriendo el comando:

\lstset{language=bash}
\begin{lstlisting}
docker images
\end{lstlisting}

		El comando anterior, mostrará una lista de las imágenes existentes en el sistema
		mostrando la última etiqueta de la misma, el número de identificación, la fecha
		de creación y el tamaño de la imagen.
		
		Luego, para aplicarle una nueva etiqueta, se ejecuta el comando:
	
\lstset{language=bash}
\begin{lstlisting}
docker tag <IMAGE_ID> <NUEVA_ETIQUETA>
\end{lstlisting}	
	
	\subsection{Docker Compose\cite{DockerComposeDocumentation}}
	
		Docker Compose es una herramienta que permite correr un sistema formado por
		múltiples contenedores. Para ello, se debe crear un archivo \emph{.yml} en el
		que se definan los servicios con los que va a contar la aplicación. Cada
		servicio estará formado por un \emph{contenedor} corriendo una \emph{imagen} de
		Docker.
		
		Para cada servicio pueden definirse nombres, puertos expuestos, conexiones de
		red, etcétera, luego, con los siguientes comandos se puede operar con el sistema.
		
		Para una lista completa de los comandos de Docker Compose, acceder a
		\href{https://docs.docker.com/compose/reference/}{Docker Compose Command-Line
		Reference}\footnote{https://docs.docker.com/compose/reference/}.

	\subsection{Material}
	
		La información de ésta sección ha sido extraída mayormente desde la
		documentación de Docker\cite{GetStartedDocker2016} y Docker
		Compose\cite{DockerComposeDocumentation}.
		
\section{Apache Zookeeper}
\label{section_apache_zookeeper}

	Apache Zookeeper es un servicio de coordinación de alto rendimiento para
	aplicaciones distribuidas. Expone servicios comunes, tales como nomenclatura,
	manejo de las configuraciones, sincronización, etcétera. 
	Entre otras funciones, se utiliza para implementar consenso, manejar grupos,
	elección de nodo líder y protocolos de presencia.
	
	Generalmente, los sistemas de coordinación son muy propensos a errores como
	condiciones de carrera y puntos muertos (\emph{deadlocks}). Zookeeper fue creado
	para que las aplicaciones distribuidas ya no necesiten implementar desde cero los
	servicios de sincronización.
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{./informe/introduccion/img/zookeeper/ZookeeperService}
		\caption{Arquitectura de un servicio Zookeeper\cite{Zookeeper348}}
	\end{figure}
	
	Deacuerdo a la documentación de Zookeeper, fué diseñado bajo estos cuatro
	pilares\cite{Zookeeper348}:
	\begin{itemize}
	    \item \emph{simplicidad}: Zookeeper permite la sincronización entre procesos
	    distribuidos a través de un espacio de nombres jerárquico compartido que se
	    encuentra organizado de manera similar a un sistema de archivos. El espacio
	    de nombres consiste en registros de datos (llamados \emph{znodes}) muy
	    similares a archivos y directorios.
	    \item \emph{replicación}: Como las aplicaciones distribuidas que coordina,
	    Zookeeper también esta diseñado para ser ejecutado de manera distribuida en
	    un conjunto de servidores. Cada uno de ellos mantiene en memoria una imagen
	    de estado con los registros de las transacciones y además, guarda capturas en
	    un almacenamiento permanente. Mientras la mayoría de los servidores siga
	    funcionando, Zookeeper seguirá funcionando.
	    
	    Cada cliente, se conecta a un único servidor de Zookeeper y mantiene una
	    conexión TCP a través de la cual envía solicitudes, obtiene las respuestas y
	    obtiene mensajes de eventos. Si dicha conexión deja de funcionar, el cliente
	    se conectará a un servidor distinto.
	    \item \emph{orden}: Cada actualización en Zookeeper es marcada con un número
	    que refleja el orden de cada una de las transacciones.
	    \item \emph{rapidez}: Zookeeper es muy rápido para entornos con cargas de
	    trabajo de muchas lecturas. Su rendimiento es mucho mejor donde las lecturas
	    de datos son más comunes a las escrituras de datos, a una relación de 10 a 1.
 	\end{itemize}
 	
 	\begin{figure}[H]
		\centering
		\includegraphics[width=1\linewidth]{./informe/introduccion/img/zookeeper/ZookeeperPerformanceRW}
		\caption{Rendimiento de Zookeeper mostrando escrituras
		versus lecturas\cite{Zookeeper348}}
	\end{figure}
	
	\subsection{El espacio de nombres y el modelo de datos}
		
		El espacio de nombres de Zookeeper es muy similar a un sistema de archivos. Cada
		nombre es una secuencia de elementos de direcciones (\emph{paths}) separadas por
		una barra (\emph{/}) y cada nodo es identificado por una dirección.
				
		\begin{figure}[H]
			\centering
			\includegraphics[width=1\linewidth]{./informe/introduccion/img/zookeeper/ZookeeperNamespace}
			\caption{El espacio de nombres jerárquico de Zookeeper\cite{Zookeeper348}}
		\end{figure}
		
		A diferencia de los sistemas de archivos, cada nodo en el espacio de nombres de
		Zookeeper puede tener datos y subnodos, es como un sistemas de archivos que
		permite a un archivo ser a la vez un directorio. Debido a los objetivos por lo
		cuales Zookeeper fue diseñado, los datos almacenados en cada nodo generalemente
		son muy pequeños, en el orden de un byte a un kilobyte. Cada nodo de datos, en
		la nomenclatura de Zookeeper es llamado \emph{znode}.

		Los \emph{znodes} mantienen una estructura de datos que incluye numeros de
		version para cada cambio en los datos y marcas de tiempo para permitir
		validaciones de cache y actualizaciones coordinadas. Con cada cambio, el número
		de versión aumenta.
		
		Los datos de cada \emph{znode} son escritos y leídos de manera atómica. Las
		lecturas devuelven todos los datos asociados al \emph{znode} y las escrituras
		reemplazan todos los datos. Cada nodo, también, posee una lista de control de
		acceso (\emph{ACL, Access Control List}) que limita quienes pueden ejecutar cada
		una de las acciones.
		
	\subsection{Garantías}
	
		Dado que el objetivo de Zookeeper es ser la base para la construcción de
		servicios complejos, como un servicio de sincronización, provee un conjunto de
		garantías:
		\begin{itemize}
		    \item \emph{Consistencia Secuencial}: Todas las actualizaciones que llegan
		    desde los clientes, serán aplicadas en el orden en el que fueron enviadas.
		    \item \emph{Atomicidad}: Las actualizaciones son exitosas o fallidas. No
		    existen resultados parciales.
		    \item \emph{Única Imagen del Sistema}: Un cliente tiene la misma vista del
		    servicio Zookeeper sin importar a cual de los servidores se conecte.
		    \item \emph{Confiabildad}: Una vez que una actualización es aplicada,
		    persiste en el tiempo hasta que algún cliente sobreescribe el registro.
		    \item \emph{Actualizaciones puntuales}: El sistema garantiza a los clientes
		    que su vista del servicio estará actualizada dentro de un cierto espacio
		    temporal.
		\end{itemize}
		
	\subsection{Material}
	
		La información de ésta sección ha sido extraída mayormente desde la
		documentación de Apache Zookeeper\cite{Zookeeper348}.
	
\section{Apache Kafka}
\label{section_apache_kafka}

	Kafka es un sistema de mensajes distribuido, particionado y con
	replicación\cite{ApacheKafka090}.

	\begin{itemize}
	    \item Kafka mantiene los mensajes agrupados en categorías llamadas
	    \emph{topics.}
		\item Los productores de mensajes se llaman \emph{producers}.
		\item Los consumidores de mensajes se llaman \emph{consumers}.
		\item Kafka corre en un cluster formado por uno o mas servidores. cada uno de
		ellos es llamado \emph{broker}.
	\end{itemize}
	
	\begin{figure}[H]
		\centering
		\includegraphics[width=.5\linewidth]{./informe/introduccion/img/kafka/high_level_arch}
		\caption{Kafka, arquitectura de alto nivel\cite{ApacheKafka090}}
	\end{figure}

	\subsection{Topics}
	
		Los \emph{topics} de Kafka son categorías de mensajes para los cuales Kafka
		mantiene registros particionados.
		
		Cada partición es una secuencia ordenada e inmutable de mensajes. El número de
		orden de cada mensaje es llamado \emph{offset} e identifica unívocamente a cada
		mensaje de la partición.
		
		Kafka mantiene los mensajes publicados por un período de tiempo configurable,
		sin importar si fueron consumidos o no por algún proceso \emph{consumer}. Cada
		consumidor se encarga de mantener el \emph{offset} y tiene libertad para ir
		hacia atrás y hacia adelante en los mensajes publicados para procesarlos.
		
		Tener los mensajes de un \emph{topic} particionados permite separar el
		\emph{topic} en varios servidores. Ésto permite manejar grandes volumenes de
		datos y además otorogar un nivel superior de paralelismo.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=.5\linewidth]{./informe/introduccion/img/kafka/kafka_topics}
			\caption{Topics en Kafka\cite{ApacheKafka090}}
		\end{figure}
		
		Cada partición está formada por un líder (\emph{leader}) que se encuentra en
		uno de los servidores y por cero o más seguidores (\emph{followers}) que
		replican al líder todo el tiempo en servidores distintos. Si el líder falla,
		alguno de los seguidores se convertirá en el nuevo líder garantizando que el
		sistema siga operando. la configuración ideal es que cada servidor sea líder de
		alguna partición y seguidor de las otras.
		
	\subsection{Productores}
		
		Los productores en Kafka son programas encargados de publicar datos en los
		\emph{topics}. El productor decide, para cada mensaje, el \emph{topic} y la
		\emph{partición} en el cual publicarlo. Generalmente la partición es elegida
		siguiendo un esquema \emph{round-robin} para lograr un óptimo balance de carga
		entre particiones, pero se puede utilizar cualquier lógica.
		
	\subsection{Consumidores}
	
		Los sitemas de mensajería pueden ser clasificados en dos categorías,
		\emph{cola de mensajes} o \emph{publicación-subscripción}. En el primero, los
		mensajes son encolados y cada mensaje es dirigido hacia alguno de los
		consumidores. En el segundo, cada mensaje es transmitido a todos los
		consumidores. kafka maneja ambos mundos con lo que se conoce como grupos de
		consumidores (\emph{consumer groups}).
		
		Cada consumidor debe ubicarse dentro de alguno de los grupos de consumidores y
		cuando un mensaje es publicado en un \emph{topic}, es transmitido a un único
		consumidor de cada uno de los grupos de consumidores.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=.5\linewidth]{./informe/introduccion/img/kafka/kafka_consumers}
			\caption{Grupos de Consumidores\cite{ApacheKafka090}}
		\end{figure}
		
		Si todos los consumidores se encuentran en el mismo grupo, el sistema funciona
		como una cola de mensajes distribuyendo la carga entre cada uno de los
		consumidores.
		
		Si todos los consumidores se encuentran en distintos grupos, el sistema
		funciona como un sistema publicación-subscripción y todos los mensajes son
		transmitidos a todos los consumidores.
		
	\subsection{Material}
	
		La información de éste capítulo ha sido extraída mayormente desde la
		documentación de Apache Kafka 0.9 \cite{ApacheKafka090}.
		
\section{Apache Storm}
\label{section_apache_storm}
	
	Apache Storm es una herramienta de procesamiento de datos en tiempo real de
	código abierto y gratuita creada por Twitter y luego liberada en lo órbita de los
	proyectos Apache.
	
	La finalidad de Storm es proveer un mecanismo confiable para procesamiento de
	flujos de datos ilimitados, haciendo para flujos de datos (\emph{realtime stream
	processing}) lo que Hadoop hace en procesamiento por lotes (\emph{batch processing})\cite{ApacheStorm101}.
	
	Deacuerdo a su documentación, es capaz de procesar un millón de tuplas de datos
	por segundo por nodo. Provee características de escalabilidad, tolerancia a
	fallos, garantías de que todos los datos serán procesados, etcétera\cite{ApacheStorm101}.
	
	
	
	\subsection{Conceptos Básicos}
	
		En ésta sección se analizarán los conceptos básicos que definen a un programa
		Storm.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=.9\linewidth]{./informe/introduccion/img/storm/topology}
		\end{figure}
		
		\subsubsection{Topologies}
		
		Las \emph{topologías} son los contenedores de la lógica de una aplicación de
		procesamiento de datos en tiempo real, consume flujos de datos, los procesa y genera
		nuevos flujos de datos. Es el análogo a un trabajo de MapReduce de
		Hadoop\footnote{https://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html}.
		La diferencia principal con éstos últimos es que un trabajo MapReduce de
		Hadoop, eventualmente concluye mientras que las topologías pueden correr
		indefinidamente. 
		Una topología es un grafo formado por \emph{Spouts} y \emph{Bolts} conectados a
		través de \emph{Stream Groupings}.
		
		\subsubsection{Streams}
		
			Los streams son una secuencia ilimitada de tuplas de datos que son creadas y
			procesadas de manera distribuida. Los streams se definen creando un esquema
			que contenga todos los campos de datos de cada tupla que forma parte del
			stream. Las tuplas pueden contener valores enteros (\emph{integer}), bytes,
			cadenas de caracteres (\emph{strings}), valores booleanos, etcétera.
		
		\subsubsection{Spouts}
		
			Los spouts son la fuente de streams para la topología. Generalemente leen
			tuplas de datos desde una fuente externa y las emiten dentro de la topología
			para que sea procesada. Los spouts pueden ser:
			\begin{itemize}
			    \item \textbf{reliable} (confiable): es un spout capaz de reenviar una
			    tupla si Storm falló en procesarla.
			    \item \textbf{unreliable} (no confiable): el spout \emph{se olvida} de las
			    tuplas en el momento en el que las emite hacia la topología.
			\end{itemize}
		
		\subsubsection{Bolts}
	
			Dentro de una topología, todo el procesamiento sobre los datos es realizado en
			los bolts. Los bolts pueden ser programados para realizar cualquier tarea como
			filtrado, agregación, uniones con bases de datos, funciones, etcétera.
			Los bolts reciben uno o varios streams de datos y pueden emitir nuevamente uno
			o varios de ellos.
	
		\subsubsection{Stream Grouping}
		
			Al definir una topología, es necesaria especificar que streams debe recibir
			como entrada cada uno de los bolts. Los \emph{stream groupings} definen como
			los streams deben ser particionados en las tareas de cada bolt.
			
			Existen ocho \emph{stream groupings} predefinidos pero existe la posibilidad
			de crear nuevos implementando la interfaz \emph{CustomStreamGrouping}.
			\begin{itemize}
			    \item \emph{Shuffle grouping}: Las tuplas son distribuidas aleatoriamente
			    en las tareas de los bolts de manera tal que se garantice que todos los
			    bolts reciben las misma cantidad de tuplas.
			    
			    \item \emph{Fields grouping}: El stream es particionado deacuerdo a los
			    campos de datos que contenga la tupla. Por ejemplo, si la tupla contiene
			    un campo llamado \emph{usuario} y se agrupa el stream por el campo
			    \emph{usuario}, todos aquellas tuplas que tengan el mismo valor en dicho
			    campo serán procesadas por el mismo bolt.
			    
			    \item \emph{Partial Key grouping}: El stream es particionado de la misma
			    manera que en el caso de \emph{Fields grouping} solo que la carga es
			    balanceada entre dos bolts para proporcionar una mejor utilización de los
			    recursos.
			    
			    \item \emph{All grouping}: El stream de datos es replicado en TODAS las
			    tareas de los bolts.
			    
			    \item \emph{Global grouping}: El stream completo es dirigido hacia una
			    única tarea de un bolt.
			    
			    \item \emph{None grouping}: Al utilizar esta forma de agrupamiento, se
			    está indicando que no es importante como el stream es dirigido hacia los
			    bolts.
			    
			    \item \emph{Direct grouping}: En éste caso, el productor de la tupla de
			    datos decide a que tarea del bolt consumidor desea enviar la tupla.
			    
			    \item \emph{Local grouping}: Si el bolt de destino tiene una o más tareas
			    en el mismo proceso \emph{worker}, las tuplas irán aleatoriamente hacia
			    alquellas tareas que estén siendo ejecutadas. En caso contrario, se
			    comportará como un \emph{Shuffle grouping}.
			\end{itemize}
	
		\subsubsection{Tasks}
		
			Cada spout o bolt ejecuta sus tareas en el cluster de Storm. Cada tarea
			corresponde con un hilo de ejecución (\emph{thread}) y los \emph{Stream
			groupings} definen como las tuplas viajan entre las tareas.
			
		\subsubsection{Workers}
		
			Las topologías corren sobre uno o más procesos \emph{worker}. Cada uno de
			estos procesos es una JVM física que ejecuta un subconjunto de las tareas de
			la topología.
		
	\subsection{Material}
	
		La información de éste capítulo ha sido extraída mayormente desde la
		documentación de Apache Storm 1.0 \cite{ApacheStorm101}.
